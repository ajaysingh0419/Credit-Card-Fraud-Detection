{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (959349404.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter nbconvert \\\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "data": {}
    }
   ],
   "source": [
    "jupyter nbconvert \\\n",
    "  --ClearMetadataPreprocessor.enabled=True \\\n",
    "  --inplace \\\n",
    "  \"FINAL PROJECT (NL -_ SQL -_ Visualizations) (1).ipynb\"\n",
    "\n",
    "jupyter nbconvert \\\n",
    "  --ClearMetadataPreprocessor.enabled=True \\\n",
    "  --inplace \\\n",
    "  \"FINAL GENERATIVE AI PROJECT (1).ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFWbpzsFD37o",
    "outputId": "31f7e31e-80b9-407d-a0a5-1ee2e2d9dd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "data": {}
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fPHNse61DhqN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset\n",
    "file_path = \"/content/drive/MyDrive/Credit Card Data.csv\"   # update path as needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 2. Basic cleaning\n",
    "# Ensure correct dtypes\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "\n",
    "# Create some helper features\n",
    "df['age'] = (df['trans_date_trans_time'].dt.year - df['dob'].dt.year)\n",
    "df['tx_hour'] = df['trans_date_trans_time'].dt.hour\n",
    "df['tx_dayofweek'] = df['trans_date_trans_time'].dt.dayofweek  # 0=Mon\n",
    "\n",
    "# Sort by user + time\n",
    "df = df.sort_values(['cc_num', 'trans_date_trans_time']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "QkYoHsDpEL_I",
    "outputId": "cc92b4c8-b5a2-4b3e-8b16-309ab1734d2d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "user_profiles"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-10c860e7-f9ac-40be-88be-8b081348c7bb\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>n_legit_tx</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>mean_spent</th>\n",
       "      <th>std_spent</th>\n",
       "      <th>min_spent</th>\n",
       "      <th>max_spent</th>\n",
       "      <th>median_spent</th>\n",
       "      <th>age_mean</th>\n",
       "      <th>city_pop_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_pct_shopping_pos</th>\n",
       "      <th>cat_pct_travel</th>\n",
       "      <th>tb_pct_afternoon</th>\n",
       "      <th>tb_pct_evening</th>\n",
       "      <th>tb_pct_morning</th>\n",
       "      <th>tb_pct_night</th>\n",
       "      <th>main_state</th>\n",
       "      <th>main_city</th>\n",
       "      <th>mean_lat</th>\n",
       "      <th>mean_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>1509</td>\n",
       "      <td>83143.74</td>\n",
       "      <td>55.098569</td>\n",
       "      <td>120.422174</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3075.09</td>\n",
       "      <td>36.66</td>\n",
       "      <td>33.277005</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098741</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>0.361829</td>\n",
       "      <td>0.332671</td>\n",
       "      <td>0.157058</td>\n",
       "      <td>0.148443</td>\n",
       "      <td>WY</td>\n",
       "      <td>Fort Washakie</td>\n",
       "      <td>43.0048</td>\n",
       "      <td>-108.8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60422928733</td>\n",
       "      <td>1519</td>\n",
       "      <td>98140.02</td>\n",
       "      <td>64.608308</td>\n",
       "      <td>83.453978</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1290.37</td>\n",
       "      <td>52.15</td>\n",
       "      <td>77.276498</td>\n",
       "      <td>46944.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099408</td>\n",
       "      <td>0.036208</td>\n",
       "      <td>0.205398</td>\n",
       "      <td>0.196182</td>\n",
       "      <td>0.292298</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>SC</td>\n",
       "      <td>North Augusta</td>\n",
       "      <td>33.6028</td>\n",
       "      <td>-81.9748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60423098130</td>\n",
       "      <td>500</td>\n",
       "      <td>54075.55</td>\n",
       "      <td>108.151100</td>\n",
       "      <td>1211.999695</td>\n",
       "      <td>1.01</td>\n",
       "      <td>27119.77</td>\n",
       "      <td>34.68</td>\n",
       "      <td>61.266000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>OK</td>\n",
       "      <td>Amorita</td>\n",
       "      <td>36.9412</td>\n",
       "      <td>-98.2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60427851591</td>\n",
       "      <td>514</td>\n",
       "      <td>49483.82</td>\n",
       "      <td>96.272023</td>\n",
       "      <td>90.327352</td>\n",
       "      <td>20.74</td>\n",
       "      <td>569.40</td>\n",
       "      <td>76.36</td>\n",
       "      <td>43.278210</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091440</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.268482</td>\n",
       "      <td>0.233463</td>\n",
       "      <td>0.284047</td>\n",
       "      <td>0.214008</td>\n",
       "      <td>OK</td>\n",
       "      <td>Burns Flat</td>\n",
       "      <td>35.3492</td>\n",
       "      <td>-99.1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60487002085</td>\n",
       "      <td>496</td>\n",
       "      <td>25160.11</td>\n",
       "      <td>50.726028</td>\n",
       "      <td>65.843969</td>\n",
       "      <td>1.02</td>\n",
       "      <td>750.39</td>\n",
       "      <td>35.64</td>\n",
       "      <td>47.360887</td>\n",
       "      <td>233060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070565</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.332661</td>\n",
       "      <td>0.344758</td>\n",
       "      <td>0.167339</td>\n",
       "      <td>0.155242</td>\n",
       "      <td>MS</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>32.3739</td>\n",
       "      <td>-90.1293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 32 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10c860e7-f9ac-40be-88be-8b081348c7bb')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-10c860e7-f9ac-40be-88be-8b081348c7bb button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-10c860e7-f9ac-40be-88be-8b081348c7bb');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-a15ddbed-04c1-4ca5-93da-db819643ea85\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a15ddbed-04c1-4ca5-93da-db819643ea85')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-a15ddbed-04c1-4ca5-93da-db819643ea85 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        cc_num  n_legit_tx  total_spent  mean_spent    std_spent  min_spent  \\\n",
       "0  60416207185        1509     83143.74   55.098569   120.422174       1.02   \n",
       "1  60422928733        1519     98140.02   64.608308    83.453978       1.04   \n",
       "2  60423098130         500     54075.55  108.151100  1211.999695       1.01   \n",
       "3  60427851591         514     49483.82   96.272023    90.327352      20.74   \n",
       "4  60487002085         496     25160.11   50.726028    65.843969       1.02   \n",
       "\n",
       "   max_spent  median_spent   age_mean  city_pop_mean  ...  \\\n",
       "0    3075.09         36.66  33.277005         1645.0  ...   \n",
       "1    1290.37         52.15  77.276498        46944.0  ...   \n",
       "2   27119.77         34.68  61.266000           83.0  ...   \n",
       "3     569.40         76.36  43.278210         2142.0  ...   \n",
       "4     750.39         35.64  47.360887       233060.0  ...   \n",
       "\n",
       "   cat_pct_shopping_pos  cat_pct_travel  tb_pct_afternoon  tb_pct_evening  \\\n",
       "0              0.098741        0.019881          0.361829        0.332671   \n",
       "1              0.099408        0.036208          0.205398        0.196182   \n",
       "2              0.052000        0.044000          0.258000        0.292000   \n",
       "3              0.091440        0.040856          0.268482        0.233463   \n",
       "4              0.070565        0.028226          0.332661        0.344758   \n",
       "\n",
       "   tb_pct_morning  tb_pct_night  main_state      main_city  mean_lat  \\\n",
       "0        0.157058      0.148443          WY  Fort Washakie   43.0048   \n",
       "1        0.292298      0.306122          SC  North Augusta   33.6028   \n",
       "2        0.236000      0.214000          OK        Amorita   36.9412   \n",
       "3        0.284047      0.214008          OK     Burns Flat   35.3492   \n",
       "4        0.167339      0.155242          MS        Jackson   32.3739   \n",
       "\n",
       "   mean_long  \n",
       "0  -108.8964  \n",
       "1   -81.9748  \n",
       "2   -98.2458  \n",
       "3   -99.1880  \n",
       "4   -90.1293  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to legitimate transactions\n",
    "df_legit = df[df['is_fraud'] == 0].copy()\n",
    "\n",
    "def build_user_profiles(df_legit):\n",
    "    # Basic numeric stats\n",
    "    agg_numeric = df_legit.groupby('cc_num').agg(\n",
    "        n_legit_tx=('amt', 'count'),\n",
    "        total_spent=('amt', 'sum'),\n",
    "        mean_spent=('amt', 'mean'),\n",
    "        std_spent=('amt', 'std'),\n",
    "        min_spent=('amt', 'min'),\n",
    "        max_spent=('amt', 'max'),\n",
    "        median_spent=('amt', 'median'),\n",
    "        age_mean=('age', 'mean'),\n",
    "        city_pop_mean=('city_pop', 'mean')\n",
    "    )\n",
    "\n",
    "    # Category distribution (% of transactions by category)\n",
    "    cat_counts = (\n",
    "        df_legit.groupby(['cc_num', 'category'])['amt']\n",
    "        .count()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "    cat_pct = cat_counts.div(cat_counts.sum(axis=1), axis=0)\n",
    "    cat_pct.columns = [f\"cat_pct_{c}\" for c in cat_pct.columns]\n",
    "\n",
    "    # Time-of-day distribution\n",
    "    # Buckets: night(0-6), morning(6-12), afternoon(12-18), evening(18-24)\n",
    "    def time_bucket(h):\n",
    "        if 0 <= h < 6:\n",
    "            return 'night'\n",
    "        elif 6 <= h < 12:\n",
    "            return 'morning'\n",
    "        elif 12 <= h < 18:\n",
    "            return 'afternoon'\n",
    "        else:\n",
    "            return 'evening'\n",
    "\n",
    "    df_legit['time_bucket'] = df_legit['tx_hour'].apply(time_bucket)\n",
    "\n",
    "    tb_counts = (\n",
    "        df_legit.groupby(['cc_num', 'time_bucket'])['amt']\n",
    "        .count()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "    tb_pct = tb_counts.div(tb_counts.sum(axis=1), axis=0)\n",
    "    tb_pct.columns = [f\"tb_pct_{c}\" for c in tb_pct.columns]\n",
    "\n",
    "    # Geography: main state/city, avg lat/long\n",
    "    geo_agg = df_legit.groupby('cc_num').agg(\n",
    "        main_state=('state', lambda x: x.value_counts().idxmax()),\n",
    "        main_city=('city', lambda x: x.value_counts().idxmax()),\n",
    "        mean_lat=('lat', 'mean'),\n",
    "        mean_long=('long', 'mean')\n",
    "    )\n",
    "\n",
    "    # Merge all\n",
    "    user_profiles = (\n",
    "        agg_numeric\n",
    "        .join(cat_pct, how='left')\n",
    "        .join(tb_pct, how='left')\n",
    "        .join(geo_agg, how='left')\n",
    "    ).reset_index()  # keep cc_num as a column\n",
    "\n",
    "    return user_profiles\n",
    "\n",
    "user_profiles = build_user_profiles(df_legit)\n",
    "user_profiles.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fhxUo0chEUF4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Merge user profiles back to all transactions\n",
    "df_model = df.merge(\n",
    "    user_profiles,\n",
    "    on='cc_num',\n",
    "    how='left',\n",
    "    suffixes=('', '_prof')\n",
    ")\n",
    "\n",
    "# Select columns for the classifier\n",
    "feature_cols_cat = ['category', 'state', 'city', 'job', 'gender']\n",
    "feature_cols_num = [\n",
    "    'amt', 'age', 'city_pop', 'tx_hour', 'tx_dayofweek',\n",
    "    'n_legit_tx', 'total_spent', 'mean_spent', 'std_spent',\n",
    "    'min_spent', 'max_spent', 'median_spent',\n",
    "    'mean_lat', 'mean_long'\n",
    "] + [c for c in df_model.columns if c.startswith('cat_pct_') or c.startswith('tb_pct_')]\n",
    "\n",
    "# Label encode categorical vars\n",
    "df_model_enc = df_model.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in feature_cols_cat:\n",
    "    le = LabelEncoder()\n",
    "    # Get all unique values from original data\n",
    "    original_classes = df_model_enc[col].astype(str).unique()\n",
    "    # Add a placeholder for unknown values that might appear in synthetic data\n",
    "    # Ensuring 'UNKNOWN_CATEGORY' is part of the classes the encoder knows\n",
    "    combined_classes = np.append(original_classes, 'UNKNOWN_CATEGORY')\n",
    "    le.fit(combined_classes) # Fit on all possible original + 'UNKNOWN_CATEGORY'\n",
    "\n",
    "    df_model_enc[col] = le.transform(df_model_enc[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "X = df_model_enc[feature_cols_num + feature_cols_cat]\n",
    "y = df_model_enc['is_fraud'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnVEEUi0EZHw",
    "outputId": "450b4b79-7017-421d-9910-3b5cd87126f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RandomForest baseline (original data only) ===\n",
      "Confusion matrix:\n",
      " [[257805     29]\n",
      " [   407   1094]]\n",
      "Baseline FPR (RandomForest): 0.00011247546871242737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9984    0.9999    0.9992    257834\n",
      "           1     0.9742    0.7288    0.8338      1501\n",
      "\n",
      "    accuracy                         0.9983    259335\n",
      "   macro avg     0.9863    0.8644    0.9165    259335\n",
      "weighted avg     0.9983    0.9983    0.9982    259335\n",
      "\n",
      "\n",
      "=== GradientBoosting baseline (original data only) ===\n",
      "Confusion matrix:\n",
      " [[257716    118]\n",
      " [   434   1067]]\n",
      "Baseline FPR (GradientBoosting): 0.0004576588037264286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9983    0.9995    0.9989    257834\n",
      "           1     0.9004    0.7109    0.7945      1501\n",
      "\n",
      "    accuracy                         0.9979    259335\n",
      "   macro avg     0.9494    0.8552    0.8967    259335\n",
      "weighted avg     0.9978    0.9979    0.9977    259335\n",
      "\n",
      "\n",
      "=== LogisticRegression baseline (original data only) ===\n",
      "Confusion matrix:\n",
      " [[245805  12029]\n",
      " [   354   1147]]\n",
      "Baseline FPR (LogisticRegression): 0.0466540487290272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9986    0.9533    0.9754    257834\n",
      "           1     0.0871    0.7642    0.1563      1501\n",
      "\n",
      "    accuracy                         0.9523    259335\n",
      "   macro avg     0.5428    0.8588    0.5659    259335\n",
      "weighted avg     0.9933    0.9523    0.9707    259335\n",
      "\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ],
     "data": {}
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer # Import SimpleImputer\n",
    "\n",
    "# Impute missing values with the median (fit on training data)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Define three baseline models\n",
    "models_baseline = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'  # handle class imbalance\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "}\n",
    "\n",
    "baseline_results = {}\n",
    "fpr_baseline = {}\n",
    "\n",
    "for name, clf in models_baseline.items():\n",
    "    print(f\"\\n=== {name} baseline (original data only) ===\")\n",
    "    # Use imputed data for training and prediction\n",
    "    clf.fit(X_train_imputed, y_train)\n",
    "    y_pred = clf.predict(X_test_imputed)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    fpr_baseline[name] = fpr\n",
    "    baseline_results[name] = {\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"fpr\": fpr,\n",
    "    }\n",
    "\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    print(f\"Baseline FPR ({name}):\", fpr)\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# For backward compatibility\n",
    "clf_baseline = models_baseline[\"RandomForest\"]\n",
    "fpr_baseline_rf = fpr_baseline[\"RandomForest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zni5HAq0FHLJ"
   },
   "outputs": [],
   "source": [
    "def profile_to_text(row):\n",
    "    # Use safe fills for NaNs\n",
    "    main_state = row.get('main_state', 'Unknown')\n",
    "    main_city = row.get('main_city', 'Unknown')\n",
    "    mean_spent = row.get('mean_spent', 0)\n",
    "    max_spent = row.get('max_spent', 0)\n",
    "    n_tx = row.get('n_legit_tx', 0)\n",
    "\n",
    "    # a few top category prefs\n",
    "    cat_cols = [c for c in user_profiles.columns if c.startswith('cat_pct_')]\n",
    "    top_cats = sorted(\n",
    "        [(c.replace('cat_pct_', ''), row[c]) for c in cat_cols],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:3]\n",
    "    cat_str = \", \".join([f\"{name} ({pct:.0%})\" for name, pct in top_cats if pct > 0])\n",
    "\n",
    "    profile = (\n",
    "        f\"User {int(row['cc_num'])} lives mainly in {main_city}, {main_state}. \"\n",
    "        f\"They have {int(n_tx)} legitimate transactions. \"\n",
    "        f\"The average transaction amount is ${mean_spent:.2f} and max is ${max_spent:.2f}. \"\n",
    "    )\n",
    "    if cat_str:\n",
    "        profile += f\"The main spending categories are: {cat_str}. \"\n",
    "    return profile\n",
    "\n",
    "user_profiles['profile_text'] = user_profiles.apply(profile_to_text, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FFoSaBiQFOXR",
    "outputId": "3a41f82c-1b76-4f6b-fe9d-8b45a0d5b925"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df_llm\",\n  \"rows\": 7506,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 688,\n        \"samples\": [\n          \"You are a fraud data generator. Given the following user profile, generate ONE realistic fraudulent credit card transaction for this user. Return ONLY a Python-style dictionary with keys matching the dataset, and set 'is_fraud' to 1.\\n\\nUSER PROFILE:\\nUser 2260801330657968 lives mainly in Paxton, MA. They have 510 legitimate transactions. The average transaction amount is $65.95 and max is $2312.21. The main spending categories are: kids_pets (12%), gas_transport (11%), shopping_pos (11%). \\n\\nFRAUD TRANSACTION:\\n\",\n          \"You are a fraud data generator. Given the following user profile, generate ONE realistic fraudulent credit card transaction for this user. Return ONLY a Python-style dictionary with keys matching the dataset, and set 'is_fraud' to 1.\\n\\nUSER PROFILE:\\nUser 4457732997086323466 lives mainly in Fiddletown, CA. They have 2038 legitimate transactions. The average transaction amount is $93.11 and max is $669.61. The main spending categories are: home (12%), grocery_pos (12%), shopping_net (9%). \\n\\nFRAUD TRANSACTION:\\n\",\n          \"You are a fraud data generator. Given the following user profile, generate ONE realistic fraudulent credit card transaction for this user. Return ONLY a Python-style dictionary with keys matching the dataset, and set 'is_fraud' to 1.\\n\\nUSER PROFILE:\\nUser 375237305371366 lives mainly in East Rochester, NY. They have 526 legitimate transactions. The average transaction amount is $67.38 and max is $1111.93. The main spending categories are: home (12%), personal_care (10%), shopping_pos (10%). \\n\\nFRAUD TRANSACTION:\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completion\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7506,\n        \"samples\": [\n          \"{ 'trans_date_trans_time': '2020-05-09 22:48:21', 'cc_num': '3565996340207976', 'merchant': 'fraud_Schmidt and Sons', 'category': 'shopping_net', 'amt': 1125.43, 'city': 'El Paso', 'state': 'TX', 'zip': '79906', 'lat': 31.8092, 'long': -106.4247, 'city_pop': 749635, 'job': 'Market researcher', 'dob': '1973-01-21 00:00:00', 'unix_time': 1368139701, 'merch_lat': 31.381532, 'merch_long': -106.195846, 'merch_zipcode': 'nan', 'is_fraud': 1 }\",\n          \"{ 'trans_date_trans_time': '2019-10-11 23:22:05', 'cc_num': '4633065159406313', 'merchant': 'fraud_Bogisich-Homenick', 'category': 'misc_net', 'amt': 702.73, 'city': 'Providence', 'state': 'RI', 'zip': '2908', 'lat': 41.8383, 'long': -71.4377, 'city_pop': 203571, 'job': 'Nurse, children's', 'dob': '1995-11-29 00:00:00', 'unix_time': 1349997725, 'merch_lat': 40.980556, 'merch_long': -71.910586, 'merch_zipcode': '11954.0', 'is_fraud': 1 }\",\n          \"{ 'trans_date_trans_time': '2020-03-11 09:49:19', 'cc_num': '3589289942931264', 'merchant': 'fraud_Jaskolski-Vandervort', 'category': 'misc_net', 'amt': 784.85, 'city': 'Spencer', 'state': 'SD', 'zip': '57374', 'lat': 43.7557, 'long': -97.5936, 'city_pop': 343, 'job': 'Development worker, international aid', 'dob': '1972-03-05 00:00:00', 'unix_time': 1362995359, 'merch_lat': 43.25999, 'merch_long': -98.429235, 'merch_zipcode': '57313.0', 'is_fraud': 1 }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df_llm"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8c86dc14-fc46-47f0-b7c8-6506b0ce9f3d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a fraud data generator. Given the foll...</td>\n",
       "      <td>{ 'trans_date_trans_time': '2019-03-01 01:32:5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a fraud data generator. Given the foll...</td>\n",
       "      <td>{ 'trans_date_trans_time': '2019-03-01 02:42:2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a fraud data generator. Given the foll...</td>\n",
       "      <td>{ 'trans_date_trans_time': '2019-03-01 23:06:5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a fraud data generator. Given the foll...</td>\n",
       "      <td>{ 'trans_date_trans_time': '2019-03-02 22:10:3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a fraud data generator. Given the foll...</td>\n",
       "      <td>{ 'trans_date_trans_time': '2019-03-02 22:10:5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c86dc14-fc46-47f0-b7c8-6506b0ce9f3d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8c86dc14-fc46-47f0-b7c8-6506b0ce9f3d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8c86dc14-fc46-47f0-b7c8-6506b0ce9f3d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-ca600443-f898-4fe3-b1cb-25dc5386e425\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca600443-f898-4fe3-b1cb-25dc5386e425')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-ca600443-f898-4fe3-b1cb-25dc5386e425 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  You are a fraud data generator. Given the foll...   \n",
       "1  You are a fraud data generator. Given the foll...   \n",
       "2  You are a fraud data generator. Given the foll...   \n",
       "3  You are a fraud data generator. Given the foll...   \n",
       "4  You are a fraud data generator. Given the foll...   \n",
       "\n",
       "                                          completion  \n",
       "0  { 'trans_date_trans_time': '2019-03-01 01:32:5...  \n",
       "1  { 'trans_date_trans_time': '2019-03-01 02:42:2...  \n",
       "2  { 'trans_date_trans_time': '2019-03-01 23:06:5...  \n",
       "3  { 'trans_date_trans_time': '2019-03-02 22:10:3...  \n",
       "4  { 'trans_date_trans_time': '2019-03-02 22:10:5...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud = df[df['is_fraud'] == 1].copy()\n",
    "\n",
    "# Join profiles to fraud rows\n",
    "df_fraud = df_fraud.merge(\n",
    "    user_profiles[['cc_num', 'profile_text']],\n",
    "    on='cc_num',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "def tx_to_text(row):\n",
    "    # Convert a single transaction row into a structured text / pseudo-JSON\n",
    "    return (\n",
    "        \"{\"\n",
    "        f\" 'trans_date_trans_time': '{row['trans_date_trans_time']}',\"\n",
    "        f\" 'cc_num': '{int(row['cc_num'])}',\"\n",
    "        f\" 'merchant': '{row['merchant']}',\"\n",
    "        f\" 'category': '{row['category']}',\"\n",
    "        f\" 'amt': {row['amt']:.2f},\"\n",
    "        f\" 'city': '{row['city']}',\"\n",
    "        f\" 'state': '{row['state']}',\"\n",
    "        f\" 'zip': '{row['zip']}',\"\n",
    "        f\" 'lat': {row['lat']},\"\n",
    "        f\" 'long': {row['long']},\"\n",
    "        f\" 'city_pop': {row['city_pop']},\"\n",
    "        f\" 'job': '{row['job']}',\"\n",
    "        f\" 'dob': '{row['dob']}',\"\n",
    "        f\" 'unix_time': {row['unix_time']},\"\n",
    "        f\" 'merch_lat': {row['merch_lat']},\"\n",
    "        f\" 'merch_long': {row['merch_long']},\"\n",
    "        f\" 'merch_zipcode': '{row['merch_zipcode']}',\"\n",
    "        f\" 'is_fraud': 1\"\n",
    "        \" }\"\n",
    "    )\n",
    "\n",
    "prompts = []\n",
    "completions = []\n",
    "\n",
    "for _, row in df_fraud.iterrows():\n",
    "    profile_text = row['profile_text']\n",
    "    prompt = (\n",
    "        \"You are a fraud data generator. Given the following user profile, \"\n",
    "        \"generate ONE realistic fraudulent credit card transaction for this user. \"\n",
    "        \"Return ONLY a Python-style dictionary with keys matching the dataset, \"\n",
    "        \"and set 'is_fraud' to 1.\\n\\n\"\n",
    "        f\"USER PROFILE:\\n{profile_text}\\n\\n\"\n",
    "        \"FRAUD TRANSACTION:\\n\"\n",
    "    )\n",
    "    completion = tx_to_text(row)\n",
    "    prompts.append(prompt)\n",
    "    completions.append(completion)\n",
    "\n",
    "train_df_llm = pd.DataFrame({\n",
    "    \"prompt\": prompts,\n",
    "    \"completion\": completions\n",
    "})\n",
    "train_df_llm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myYejrI1FWFz",
    "outputId": "05488087-9fcc-4539-959a-241f7b83c7e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ],
     "data": {}
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "bc77f9069f144f49974145af9fcdda49",
      "b69cc128d89140ddaa7c154b9345c298",
      "13f0f6b462534fc8b8ef80ab0c9170ba",
      "744ed50494a04aa6a9d22f4e6c9185fa",
      "94f753037ddc4d3d9ceb8c74b4e6b0c2",
      "b82d0e9a3577405c82d648b1f7111637",
      "b3945eaa86f7459da809d831196223b4",
      "403429311b904f88b9155c9822f22a97",
      "094097501deb4ad19208fbf36673eb3d",
      "176a2d80bb074ba1a738c3bc2db6b66b",
      "e3bba22095624a7d87bf82893a15abb4"
     ]
    },
    "id": "1IGd8VhTFdk9",
    "outputId": "28ca7d60-0064-494b-c551-a352dccd6d18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7506 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def format_example(ex):\n",
    "    # Simple instruction-tuning style\n",
    "    text = ex[\"prompt\"] + ex[\"completion\"]\n",
    "    return {\"text\": text}\n",
    "\n",
    "hf_ds = Dataset.from_pandas(train_df_llm[['prompt', 'completion']])\n",
    "hf_ds = hf_ds.map(format_example, remove_columns=['prompt', 'completion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "771d07d8b1d84015a279f7322ebd460c",
      "774c2dab981f4352b57d53f65a168827",
      "20a3d12ed01b4ba6b66bcb22997341fb",
      "bb201f85f53a443b9f77a61792b2cad8",
      "8bf15be823e34d5881b997dc8a0792ba",
      "cca627dd901d4902899d6f7c325f53df",
      "95fcbd26136646518c7cf9728a7869a6",
      "0afc8eff80c34a96a203620b6fb0c2e1",
      "f800eb4646974705964a378ecfff88c4",
      "06237284bab749f8bb127e3265d33e5b",
      "2d6a99740d6243ab94e585bd730a13ad",
      "dd34a78ef0984e099982f5f10e3d2e58",
      "65da842660f74c988bba98f08729fcd1",
      "bdcc9a84c70e45bbaa1c75bce5496cc2",
      "66ff7249f7a74c31891f854d5ce207fd",
      "82121410d5c848ff98967f4f538eea0f",
      "82dd4bf1d0a842d1b5d49d1122fdd95d",
      "f2f7c459d1984f0aa6a6ec8fecb9fdf3",
      "a5d03b2579494f43bebbbaf4abe2de11",
      "48bdf1e1ccd741dd867ebb9fb2085585",
      "a916f4dea0724c1f9311064aaf7b69ac",
      "f3f30c2031004446bdb6785f6391386c",
      "73512ed1c3974e608519c2145e6145bf",
      "459fd81688c84887811be643ff92707c",
      "0d10deb5860140e29510b16c126d1911",
      "3b4c8248840143e09b6e151eeb123531",
      "f67530f62200457e8cef8ca5a3b79b7b",
      "4404c265d92b4b79927cc79831d24dd8",
      "c886c305d8de437ba0bfd9416102bf1a",
      "c531b0d1ea404a379071590ad423bffa",
      "b9e9a5f7554d4f35a1fe10023077e3ab",
      "56aa6d584011415f9aad34996d44ad78",
      "475d3ee015d141cc93b328ed0dfc5911",
      "02b7c2fd9c1141ec8d396e09b3651e90",
      "12820fc5697d48679582e8fda6b87234",
      "ecae1069b81d467caf4c4ecbf80c6418",
      "79b40a413cfd43489df870742b988ff6",
      "6fdc5f755a274bfbb68b88edc372302a",
      "4c2a547852fe4f058463ae6b57626913",
      "b362c623ecf7436d8150c8b5e87d208c",
      "54e66acd681244c5b3fd52fe302cd963",
      "1fa3b0cd48424ef9aa529341769f9232",
      "cad8e1478c784592811694d3dd24d2ba",
      "6bdc03d95ac545c29111055e7b5bb967",
      "0585ea8672c74d6fa1297d703d2bc089",
      "e2ca38b48f394384ae5289df219d59a4",
      "94040b983a5247678cece92bc1a3b8f5",
      "98deb262848247239c00c4b38e0a2d21",
      "09afe839d86747bb9327bf35f365750b",
      "59b63395730b48ee90a179a65f1a16f8",
      "706e0446783649f290531c715b59af6d",
      "46e3094d091e4ea8bff7d1becec4e133",
      "c892bfea03f44d4494eab9af209711aa",
      "99433ff982c44a2b90119a6a441eb327",
      "8de09f99997e464c95381407180021c8",
      "20931c3b25b9466e86e86794ae799de4",
      "116140bec34f4a888c45c1eea188183c",
      "aaa7fea5603b419e97f7f6eaa9c53130",
      "a40e359bfd9547b7b6be04b8fb905c2b",
      "0e24dd95f53041fdb6d88392bd28140a",
      "33a3056ec97c428d91355cf087f6c4d9",
      "694460d16c664910a6db148de7b75bb1",
      "bbe3263925474a82840657128bef34de",
      "4fb7e595531846cf92d651e23cb41e90",
      "2cfa51ef4c9b419fa89e79cc4099f29d",
      "47e3f7bab93f47dfb859c872ac841c2c",
      "73c3c4d2c6054a38b370f47bf2d36f70",
      "0bb3e4d6054740f48825b09ded36613a",
      "4f7e9551f07648139f2ec9bf9aa70374",
      "e4d0a8c8251942e0b1bf4dbe5050b034",
      "4f5bd8f29228417fb8cde85394de0957",
      "823584880fd74cc8b63beebebc987eb6",
      "9e95cd54a0f3412ea3911bc6047deb8e",
      "69cb7f3ee40d4287ba88bcc1d61cd46f",
      "def38dd78b2145258698f2be59d199fd",
      "4152d2416b2343098512acadec471fce",
      "fde04c9815df414397182c47c952e87c",
      "7b40236daadc4f5f952c716ee84afdf1",
      "dc409a5525cc4fe9b2dabd0b8aa8effa",
      "8967de757b534f629408674659bb5fcb",
      "997545a77916452fb58d26fe844519c7",
      "d64dffb92b604f588b1e46580810134e",
      "eadde44933234ea68e0ba5c6525cb066",
      "486c4e15875c4a31be58a8eadf1e1a47",
      "20a29c1d127e4803a934fdeca75ba70a",
      "00a3740e813e41b5be02b10edf73f40a",
      "1dc4cfd8223c496d82c6278598570aa4",
      "49f626bb1f3047f782ee1be63fa1743f",
      "a833aed549cf43fca8b653119c63ef2d",
      "052426b42e59489eaa7bdb3fcc30be0c",
      "9a296ea5bde540ebae02b4bb7a0a6af9",
      "d88640ffa65847dda50eeb62cd3536bb",
      "2779338bd392425caa0c1b175d8e663f",
      "4f7915e5529945419db710020b6726fe",
      "9a632b7ed2ac4533a3a60abdfcccc7e3",
      "6a6ab532eb004159b2797d0544847dce",
      "985b51ec94aa4acf87942c2ea37c5480",
      "3d1e2acbf7814224999be6888b2048e4",
      "003e3304667d417092a6751dd30b2e28",
      "abcb1ae22cce4da6ba5f6e5c18eff0d3",
      "b28847253d05425aaf05d10bf2197288",
      "d5a2a3f2d26f4d8d902c6d4718908fde",
      "acff764fa0714e009b5091ab3ef14b69",
      "d5763c666d114d539ea942ea4bba6fc5",
      "f3172a549afa4ea2840229f0b26b06ba",
      "64855c81485f4801a695b6baf46b1e01",
      "df3356ffcf074775b221a06090b18b09",
      "e6ef254879624a4ba12ed7f77b19eabb",
      "4395ce4dbedb4185b285267c2b58808d",
      "571ba9838a17429a84c06a6d692f7d5b",
      "e339ea8004b8453caf63b30ba6413b28",
      "76a82f12d7524048b4046954f7e7a65c",
      "e0621af8cb35497fbe6ab6074721a076",
      "9b8552bcbfb94ec8b185f1e289824ade",
      "e0dbc021871c407a80e845fdf06faf76",
      "68feef2293b3410f8394f242909ebadd",
      "48bc9661eca84184af2876e87918d99e",
      "6a4331b924be440e8f036244e0ce1743",
      "3d919812e01244d48f289cad4295cb2a",
      "56c24ccf6294499793ae0f2e2521d133",
      "52e2fdd360894f3cb4a01bb83898e089",
      "81320624b4784a9a9f05d3896506e091",
      "bbd36f2b316942bdadff965334d052be",
      "0f6a201ee546430ea271ade89d37d5ee",
      "987f25fee8354c57aaf2d483f87f2f94",
      "ea46d835485b41cbbdebb0323bcb0d57",
      "b04d710dbc554b8f970fdd81098f5389",
      "ee986c6f20fe486a84f3888068fad1fc",
      "806c96903ef747bf937b87f2ac6a0a4d",
      "68bf8c6b3b2044d4a267f82192f041d0",
      "6f75e689aa0d4194bb403cf122296a1a",
      "07dc10b21b34464d9b538d7d19ddc301",
      "164742a0359e4a2f8d576e7a5eb631df",
      "d8522925e09c4730b837a991416132d9",
      "36718ab54fa645499ff9271530e6e723",
      "38143a5dfdc0490daa9e1faeeba0a825",
      "a3bcce386fee4af69a7c15248da60c82",
      "405f28ccc2ee47828862261395e0b1a1",
      "528b76ff64964cedafd7287ffefd6b90",
      "3525f0902a2b44d2bafbb987b828bfe4",
      "90ab29205a7b4462a4ea8af6e68d5ccd",
      "c713ecda6f90419893710ab20af9e0c0",
      "40ecbc1b82c543d790eeb5fcf87004f2",
      "1b817557a12e4cd087010e0c1473ecbc",
      "ee616a6790154e608f357ea7b5d24da3",
      "ce4673d7a4fa4658975419ffa15a5c0b",
      "bc0ca282c8a84fc789b282943535b543",
      "e622d5dc31e94a7c8cb78a6811360bca",
      "8e272c984fdf47d383701514525abbdc",
      "f593f460d0f74129abe2ebef665924f9",
      "1d63a577bd2d4c2cb303d0edd45e345a",
      "9a96978903dc4445b2c0bbe591da6c3b",
      "ef816205fa3f41ddbd783d8a2426c506",
      "dddc578d192a4d978f8da3b0c9088390"
     ]
    },
    "id": "Bq4IdFoSFhj6",
    "outputId": "62d9ea02-e0dc-40e5-a9e7-3b04183c9f34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ],
     "data": {}
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7506 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,621,440 || all params: 2,782,305,280 || trainable%: 0.0942\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33momkargp1\u001b[0m (\u001b[33momkargp1-umbc\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ],
     "data": {}
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251203_160947-8x1y2r45</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/omkargp1-umbc/huggingface/runs/8x1y2r45' target=\"_blank\">floral-brook-5</a></strong> to <a href='https://wandb.ai/omkargp1-umbc/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/omkargp1-umbc/huggingface' target=\"_blank\">https://wandb.ai/omkargp1-umbc/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/omkargp1-umbc/huggingface/runs/8x1y2r45' target=\"_blank\">https://wandb.ai/omkargp1-umbc/huggingface/runs/8x1y2r45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ],
     "data": {}
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [470/470 1:07:19, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.904300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.833200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.812000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./fraud-llm/tokenizer_config.json',\n",
       " './fraud-llm/special_tokens_map.json',\n",
       " './fraud-llm/vocab.json',\n",
       " './fraud-llm/merges.txt',\n",
       " './fraud-llm/added_tokens.json',\n",
       " './fraud-llm/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "model_name = \"microsoft/phi-2\"  # or another small causal LM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_ds = hf_ds.map(tokenize_fn, batched=True, remove_columns=['text'])\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Use BitsAndBytesConfig as recommended by the warning and for better device handling\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16, # or torch.bfloat16 if GPU supports it\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0} # Explicitly set device to GPU 0\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # adjust depending on model\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fraud-llm\",\n",
    "    per_device_train_batch_size=2, # Reduced batch size\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=0.5,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    save_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save adapter\n",
    "trainer.save_model(\"./fraud-llm\")\n",
    "tokenizer.save_pretrained(\"./fraud-llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "d1462e65cdf84a1990346c4c89e10eb8",
      "78aa5cfb186a40609412b1652f52f823",
      "cfb3cc8cd220405ab3bc6fa02c2e4b60",
      "b3c130b8f5d74780a0344f980c876b1e",
      "5796c47b8d9d438395a96b05825f1f0c",
      "62d7cd4dcf564e81a58f912275b0eb39",
      "d663a872957648d98bfce10808eb234f",
      "63dd73e40c714448812e968092d8190e",
      "f2e29cdd1ca544b3aea65644adcea8cc",
      "22a931c6e8794ec8b29679f3419355e5",
      "3446c3ffc6184246944b482db4e128f0"
     ]
    },
    "id": "Uz0PlH1cc1hq",
    "outputId": "305551d9-53a5-4e82-9209-d57f5a217b04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ],
     "data": {}
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import ast  # to safely parse the Python dict string\n",
    "\n",
    "# Reload model + tokenizer (with LoRA)\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"./fraud-llm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fraud-llm\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_fraud_for_user(profile_text, num_samples=10, max_new_tokens=256):\n",
    "    prompt = (\n",
    "        \"You are a fraud data generator. Given the following user profile, \"\n",
    "        \"generate ONE realistic fraudulent credit card transaction for this user. \"\n",
    "        \"Return ONLY a Python-style dictionary with keys matching the dataset, \"\n",
    "        \"and set 'is_fraud' to 1.\\n\\n\"\n",
    "        f\"USER PROFILE:\\n{profile_text}\\n\\n\"\n",
    "        \"FRAUD TRANSACTION:\\n\"\n",
    "    )\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=num_samples\n",
    "    )\n",
    "\n",
    "    gen_texts = []\n",
    "    for i in range(num_samples):\n",
    "        text = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "        # Extract only the dictionary part (after the prompt)\n",
    "        dict_str = text.split(\"FRAUD TRANSACTION:\\n\")[-1].strip()\n",
    "        gen_texts.append(dict_str)\n",
    "    return gen_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "3ade1946e1034ed6943bc5b3e159ce7a",
      "b6658b96458c419493d36c0b08e1e79f",
      "aaee8949c452491f9bd2f7a56f603fe1",
      "9f4ae99d38724e929b394f201a96d2a2",
      "8fe1c21600de48eea2e78a9e02444aa9",
      "09f487fbc74c43e6932804edd1c3f2f7",
      "d896101c2de54f4c954c8dba6c61546c",
      "9e836df73db04f0182bcc36e9ace5740",
      "43d9ec3cec494eb38ee19524be427099",
      "fa1680e080a345f099a2a1639535a8ca",
      "fd8df19ba7c84bc7a0b6ebdb41c02d1b"
     ]
    },
    "id": "HRvXWnH8c2iW",
    "outputId": "038e7d79-1268-44d3-e60d-63224b21e175"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ],
     "data": {}
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import ast  # to safely parse the Python dict string\n",
    "\n",
    "# Reload model + tokenizer (with LoRA)\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"./fraud-llm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fraud-llm\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_fraud_for_user(profile_text, num_samples=3, max_new_tokens=256):\n",
    "    prompt = (\n",
    "        \"You are a fraud data generator. Given the following user profile, \"\n",
    "        \"generate ONE realistic fraudulent credit card transaction for this user. \"\n",
    "        \"Return ONLY a Python-style dictionary with keys matching the dataset, \"\n",
    "        \"and set 'is_fraud' to 1.\\n\\n\"\n",
    "        f\"USER PROFILE:\\n{profile_text}\\n\\n\"\n",
    "        \"FRAUD TRANSACTION:\\n\"\n",
    "    )\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=num_samples\n",
    "    )\n",
    "\n",
    "    gen_texts = []\n",
    "    for i in range(num_samples):\n",
    "        text = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "        # Extract only the dictionary part (after the prompt)\n",
    "        dict_str = text.split(\"FRAUD TRANSACTION:\\n\")[-1].strip()\n",
    "        gen_texts.append(dict_str)\n",
    "    return gen_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cpe4wfZGc_Xf",
    "outputId": "b330565e-d33e-4cbe-8d19-6aa742649455"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 6) (<unknown>, line 6)\n",
      "Parse error, skipping: unterminated triple-quoted string literal (detected at line 10) (<unknown>, line 5)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid decimal literal (<unknown>, line 7)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 6) (<unknown>, line 6)\n",
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 8) (<unknown>, line 8)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 0)\n",
      "Parse error, skipping: unterminated string literal (detected at line 6) (<unknown>, line 6)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 9) (<unknown>, line 9)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 5)\n",
      "Parse error, skipping: unterminated triple-quoted string literal (detected at line 5) (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 3) (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 5) (<unknown>, line 5)\n",
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n",
      "Parse error, skipping: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 3) (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 7) (<unknown>, line 7)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unexpected indent (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unterminated string literal (detected at line 4) (<unknown>, line 4)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 5) (<unknown>, line 5)\n",
      "Parse error, skipping: unterminated string literal (detected at line 9) (<unknown>, line 9)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unexpected indent (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<unknown>, line 1)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n",
      "Parse error, skipping: unterminated string literal (detected at line 9) (<unknown>, line 9)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<unknown>, line 1)\n",
      "Parse error, skipping: unterminated string literal (detected at line 15) (<unknown>, line 15)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 5) (<unknown>, line 5)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unterminated string literal (detected at line 4) (<unknown>, line 4)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<unknown>, line 11)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 9)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unterminated string literal (detected at line 11) (<unknown>, line 11)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 4)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unexpected indent (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 5)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<unknown>, line 1)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 4) (<unknown>, line 4)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 6) (<unknown>, line 6)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<unknown>, line 1)\n",
      "Parse error, skipping: unterminated string literal (detected at line 3) (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated triple-quoted string literal (detected at line 8) (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 4)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 14) (<unknown>, line 14)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 5)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 4) (<unknown>, line 4)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 6)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 5)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 4) (<unknown>, line 4)\n",
      "Parse error, skipping: unterminated string literal (detected at line 8) (<unknown>, line 8)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 7)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 5) (<unknown>, line 5)\n",
      "Parse error, skipping: unterminated string literal (detected at line 7) (<unknown>, line 7)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unexpected indent (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated triple-quoted string literal (detected at line 12) (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 8) (<unknown>, line 8)\n",
      "Parse error, skipping: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unterminated string literal (detected at line 6) (<unknown>, line 6)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unterminated string literal (detected at line 4) (<unknown>, line 4)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 4) (<unknown>, line 4)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 5)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: unmatched '}' (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: unterminated string literal (detected at line 7) (<unknown>, line 7)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n",
      "Parse error, skipping: invalid syntax (<unknown>, line 3)\n"
     ],
     "data": {}
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_synth\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"trans_date_trans_time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"2019-06-19 22:34:57\",\n          \"2019-12-17 02:23:23\",\n          \"2019-03-13 23:41:51\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cc_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 881594714571346688,\n        \"min\": 571314334723,\n        \"max\": 4989847570577635369,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          4610050989831291,\n          676369110710,\n          38797410705641\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"merchant\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"fraud_Wattis and Sons\",\n          \"fraud_A.Hulihan and Sons\",\n          \"fraud_Schmitt, Wehrle and McShane\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"home\",\n          \"kids_pets\",\n          \"grocery_pos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 374.36925445642316,\n        \"min\": 4.57,\n        \"max\": 1054.91,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          296.96,\n          914.14,\n          4.57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"Utica\",\n          \"Southfield\",\n          \"Oak Hill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"MO\",\n          \"OK\",\n          \"CA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zip\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"24038\",\n          \"12568\",\n          \"74414\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.566562037119488,\n        \"min\": 28.5657,\n        \"max\": 44.4872,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          38.9087,\n          40.7114,\n          35.5981\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"long\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.402756366716305,\n        \"min\": -122.2423,\n        \"max\": -70.1422,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          -79.0712,\n          -76.3768,\n          -95.9071\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city_pop\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1200193,\n        \"min\": 8,\n        \"max\": 6371300,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          1434,\n          8,\n          2627086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Proprietor of a spa and health facility\",\n          \"Film and TV editor\",\n          \"Fitness instructor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dob\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"1956-07-27 00:00:00\",\n          \"1980-05-03 00:00:00\",\n          \"1972-01-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unix_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12360080,\n        \"min\": 1327334554,\n        \"max\": 1368682750,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          1349482407,\n          1367382333,\n          1329241241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"merch_lat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.541825218197273,\n        \"min\": 28.494763,\n        \"max\": 44.351272,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          39.049429,\n          40.753638,\n          34.456987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"merch_long\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.361187164227367,\n        \"min\": -122.140914,\n        \"max\": -70.248909,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          -79.593715,\n          -75.556791,\n          -95.890347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"merch_zipcode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"17340.0\",\n          \"15043.0\",\n          \"nan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_fraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_synth"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-528b7147-ea5b-44d0-9ae4-cdc77a405dcf\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>merch_zipcode</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-04 23:41:14</td>\n",
       "      <td>3512365128314616</td>\n",
       "      <td>fraud_Schneider-Reed</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>371.93</td>\n",
       "      <td>Arnold</td>\n",
       "      <td>MO</td>\n",
       "      <td>63111</td>\n",
       "      <td>38.2382</td>\n",
       "      <td>-92.6767</td>\n",
       "      <td>3814</td>\n",
       "      <td>Futures trading portfolio manager</td>\n",
       "      <td>1989-06-01 00:00:00</td>\n",
       "      <td>1327334554</td>\n",
       "      <td>37.483518</td>\n",
       "      <td>-92.077099</td>\n",
       "      <td>63935.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-17 23:58:59</td>\n",
       "      <td>3563837241599446</td>\n",
       "      <td>fraud_Lueck and Son</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>296.62</td>\n",
       "      <td>Newberg</td>\n",
       "      <td>OR</td>\n",
       "      <td>97103</td>\n",
       "      <td>44.0731</td>\n",
       "      <td>-122.2423</td>\n",
       "      <td>120862</td>\n",
       "      <td>Social policy adviser</td>\n",
       "      <td>1981-02-12 00:00:00</td>\n",
       "      <td>1347292669</td>\n",
       "      <td>43.752227</td>\n",
       "      <td>-122.140914</td>\n",
       "      <td>97106.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01 22:40:30</td>\n",
       "      <td>3568255211412877</td>\n",
       "      <td>fraud_Kovacevich, Sime and Koss</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>325.95</td>\n",
       "      <td>Leo</td>\n",
       "      <td>IN</td>\n",
       "      <td>47401</td>\n",
       "      <td>39.5708</td>\n",
       "      <td>-87.1499</td>\n",
       "      <td>1426</td>\n",
       "      <td>Musician, classical</td>\n",
       "      <td>1939-09-04 00:00:00</td>\n",
       "      <td>1338669510</td>\n",
       "      <td>39.132234</td>\n",
       "      <td>-86.965399</td>\n",
       "      <td>48456.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27 22:48:17</td>\n",
       "      <td>4989847570577635369</td>\n",
       "      <td>fraud_Gruening-Hollister</td>\n",
       "      <td>home</td>\n",
       "      <td>6.24</td>\n",
       "      <td>Prosperity</td>\n",
       "      <td>SC</td>\n",
       "      <td>29619</td>\n",
       "      <td>32.8014</td>\n",
       "      <td>-81.6017</td>\n",
       "      <td>1523</td>\n",
       "      <td>Journalist, film</td>\n",
       "      <td>1982-04-03 00:00:00</td>\n",
       "      <td>1368492097</td>\n",
       "      <td>32.180712</td>\n",
       "      <td>-82.817666</td>\n",
       "      <td>29455.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06 03:04:47</td>\n",
       "      <td>3501942333500073</td>\n",
       "      <td>fraud_Dunn, Tost and Reising</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>741.69</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85001</td>\n",
       "      <td>33.7332</td>\n",
       "      <td>-112.6457</td>\n",
       "      <td>6371300</td>\n",
       "      <td>Healthcare professional</td>\n",
       "      <td>1958-03-25 00:00:00</td>\n",
       "      <td>1353293577</td>\n",
       "      <td>34.539286</td>\n",
       "      <td>-112.283897</td>\n",
       "      <td>86116.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-528b7147-ea5b-44d0-9ae4-cdc77a405dcf')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-528b7147-ea5b-44d0-9ae4-cdc77a405dcf button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-528b7147-ea5b-44d0-9ae4-cdc77a405dcf');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-6ca24b4d-3292-44c4-a5fd-84440374f611\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ca24b4d-3292-44c4-a5fd-84440374f611')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-6ca24b4d-3292-44c4-a5fd-84440374f611 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  trans_date_trans_time               cc_num                         merchant  \\\n",
       "0   2019-03-04 23:41:14     3512365128314616             fraud_Schneider-Reed   \n",
       "1   2019-11-17 23:58:59     3563837241599446              fraud_Lueck and Son   \n",
       "2   2019-10-01 22:40:30     3568255211412877  fraud_Kovacevich, Sime and Koss   \n",
       "3   2020-02-27 22:48:17  4989847570577635369         fraud_Gruening-Hollister   \n",
       "4   2020-01-06 03:04:47     3501942333500073     fraud_Dunn, Tost and Reising   \n",
       "\n",
       "      category     amt        city state    zip      lat      long  city_pop  \\\n",
       "0  grocery_pos  371.93      Arnold    MO  63111  38.2382  -92.6767      3814   \n",
       "1  grocery_pos  296.62     Newberg    OR  97103  44.0731 -122.2423    120862   \n",
       "2  grocery_pos  325.95         Leo    IN  47401  39.5708  -87.1499      1426   \n",
       "3         home    6.24  Prosperity    SC  29619  32.8014  -81.6017      1523   \n",
       "4     misc_net  741.69     Phoenix    AZ  85001  33.7332 -112.6457   6371300   \n",
       "\n",
       "                                 job                  dob   unix_time  \\\n",
       "0  Futures trading portfolio manager  1989-06-01 00:00:00  1327334554   \n",
       "1              Social policy adviser  1981-02-12 00:00:00  1347292669   \n",
       "2                Musician, classical  1939-09-04 00:00:00  1338669510   \n",
       "3                   Journalist, film  1982-04-03 00:00:00  1368492097   \n",
       "4            Healthcare professional  1958-03-25 00:00:00  1353293577   \n",
       "\n",
       "   merch_lat  merch_long merch_zipcode  is_fraud  \n",
       "0  37.483518  -92.077099       63935.0         1  \n",
       "1  43.752227 -122.140914       97106.0         1  \n",
       "2  39.132234  -86.965399       48456.0         1  \n",
       "3  32.180712  -82.817666       29455.0         1  \n",
       "4  34.539286 -112.283897       86116.0         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_rows = []\n",
    "\n",
    "# Example: generate for 10% of users to start\n",
    "subset_profiles = user_profiles.sample(frac=0.1, random_state=42)\n",
    "\n",
    "for _, row in subset_profiles.iterrows():\n",
    "    profile_text = row['profile_text']\n",
    "    cc_num = row['cc_num']\n",
    "    gen_list = generate_fraud_for_user(profile_text, num_samples=2)\n",
    "\n",
    "    for dict_str in gen_list:\n",
    "        try:\n",
    "            tx_dict = ast.literal_eval(dict_str)\n",
    "            tx_dict['cc_num'] = cc_num  # ensure correct user id\n",
    "            # enforce fraud label\n",
    "            tx_dict['is_fraud'] = 1\n",
    "            synthetic_rows.append(tx_dict)\n",
    "        except Exception as e:\n",
    "            print(\"Parse error, skipping:\", e)\n",
    "\n",
    "df_synth = pd.DataFrame(synthetic_rows)\n",
    "df_synth.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MBaxRnZvdCjS"
   },
   "outputs": [],
   "source": [
    "# Ensure all expected columns exist\n",
    "expected_cols = df.columns  # from original dataset\n",
    "\n",
    "for col in expected_cols:\n",
    "    if col not in df_synth.columns:\n",
    "        df_synth[col] = np.nan\n",
    "\n",
    "df_synth = df_synth[expected_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Bn-inyUXdI7c"
   },
   "outputs": [],
   "source": [
    "# Combine original training set rows (using indices from earlier split) with synthetic rows\n",
    "# First, we reconstruct X_train / y_train with indices\n",
    "\n",
    "train_indices = X_train.index\n",
    "df_train_original = df_model_enc.loc[train_indices].copy()\n",
    "\n",
    "# Re-encode synthetic data with the same label encoders\n",
    "df_synth_enc = df_synth.copy()\n",
    "\n",
    "# Convert dates and create helper features if needed, matching preprocessing\n",
    "df_synth_enc['trans_date_trans_time'] = pd.to_datetime(df_synth_enc['trans_date_trans_time'])\n",
    "df_synth_enc['dob'] = pd.to_datetime(df_synth_enc['dob'])\n",
    "df_synth_enc['age'] = df_synth_enc['trans_date_trans_time'].dt.year - df_synth_enc['dob'].dt.year\n",
    "df_synth_enc['tx_hour'] = df_synth_enc['trans_date_trans_time'].dt.hour\n",
    "df_synth_enc['tx_dayofweek'] = df_synth_enc['trans_date_trans_time'].dt.dayofweek\n",
    "\n",
    "# Merge profile features for synthetic rows too\n",
    "df_synth_enc = df_synth_enc.merge(\n",
    "    user_profiles,\n",
    "    on='cc_num',\n",
    "    how='left',\n",
    "    suffixes=('', '_prof')\n",
    ")\n",
    "\n",
    "# Encode categorical features with existing label encoders\n",
    "for col, le in label_encoders.items():\n",
    "    # Ensure the column is of string type before processing to prevent FutureWarning\n",
    "    df_synth_enc[col] = df_synth_enc[col].astype(str)\n",
    "\n",
    "    # Replace unseen labels in df_synth_enc with 'UNKNOWN_CATEGORY' before transforming\n",
    "    # Use .isin() for boolean indexing for efficiency and to handle potential NaNs safely\n",
    "    unseen_mask = ~df_synth_enc[col].isin(le.classes_)\n",
    "    if unseen_mask.any(): # Check if there are any unseen labels\n",
    "        df_synth_enc.loc[unseen_mask, col] = 'UNKNOWN_CATEGORY'\n",
    "    df_synth_enc[col] = le.transform(df_synth_enc[col])\n",
    "\n",
    "# Build X_synth, y_synth\n",
    "X_synth = df_synth_enc[feature_cols_num + feature_cols_cat]\n",
    "y_synth = df_synth_enc['is_fraud'].astype(int)\n",
    "\n",
    "# Concatenate training data\n",
    "X_train_aug = pd.concat([X_train, X_synth], axis=0)\n",
    "y_train_aug = pd.concat([y_train, y_synth], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIoo5kW5dJzv",
    "outputId": "a45b405d-a34e-4871-889c-ef9dbe4f01e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RandomForest with synthetic data (augmented training set) ===\n",
      "Confusion matrix (augmented):\n",
      " [[257807     27]\n",
      " [   399   1102]]\n",
      "Augmented FPR (RandomForest): 0.00010471853983570825\n",
      "Change in FPR vs baseline: -7.756928876719125e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9985    0.9999    0.9992    257834\n",
      "           1     0.9761    0.7342    0.8380      1501\n",
      "\n",
      "    accuracy                         0.9984    259335\n",
      "   macro avg     0.9873    0.8670    0.9186    259335\n",
      "weighted avg     0.9983    0.9984    0.9982    259335\n",
      "\n",
      "\n",
      "=== GradientBoosting with synthetic data (augmented training set) ===\n",
      "Confusion matrix (augmented):\n",
      " [[257633    201]\n",
      " [   953    548]]\n",
      "Augmented FPR (GradientBoosting): 0.0007795713521102725\n",
      "Change in FPR vs baseline: 0.0003219125483838439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9963    0.9992    0.9978    257834\n",
      "           1     0.7316    0.3651    0.4871      1501\n",
      "\n",
      "    accuracy                         0.9956    259335\n",
      "   macro avg     0.8640    0.6822    0.7424    259335\n",
      "weighted avg     0.9948    0.9956    0.9948    259335\n",
      "\n",
      "\n",
      "=== LogisticRegression with synthetic data (augmented training set) ===\n",
      "Confusion matrix (augmented):\n",
      " [[245357  12477]\n",
      " [   354   1147]]\n",
      "Augmented FPR (LogisticRegression): 0.04839160079741229\n",
      "Change in FPR vs baseline: 0.0017375520683850856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9986    0.9516    0.9745    257834\n",
      "           1     0.0842    0.7642    0.1517      1501\n",
      "\n",
      "    accuracy                         0.9505    259335\n",
      "   macro avg     0.5414    0.8579    0.5631    259335\n",
      "weighted avg     0.9933    0.9505    0.9698    259335\n",
      "\n"
     ],
     "data": {}
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ],
     "data": {}
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Reuse the imputer from the baseline step (fitted on X_train) to transform\n",
    "# the augmented training data. X_test_imputed is already available.\n",
    "X_train_aug_imputed = pd.DataFrame(imputer.transform(X_train_aug), columns=X_train_aug.columns, index=X_train_aug.index)\n",
    "\n",
    "# Define the same three model types for training on augmented data\n",
    "models_augmented = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "}\n",
    "\n",
    "augmented_results = {}\n",
    "fpr_augmented = {}\n",
    "\n",
    "for name, clf in models_augmented.items():\n",
    "    print(f\"\\n=== {name} with synthetic data (augmented training set) ===\")\n",
    "    # Use the imputed augmented training data\n",
    "    clf.fit(X_train_aug_imputed, y_train_aug)\n",
    "    # Use the imputed test data from the baseline step\n",
    "    y_pred_aug = clf.predict(X_test_imputed)\n",
    "\n",
    "    cm_aug = confusion_matrix(y_test, y_pred_aug)\n",
    "    tn_a, fp_a, fn_a, tp_a = cm_aug.ravel()\n",
    "    fpr_a = fp_a / (fp_a + tn_a)\n",
    "\n",
    "    fpr_augmented[name] = fpr_a\n",
    "    augmented_results[name] = {\n",
    "        \"confusion_matrix\": cm_aug,\n",
    "        \"fpr\": fpr_a,\n",
    "    }\n",
    "\n",
    "    print(\"Confusion matrix (augmented):\\n\", cm_aug)\n",
    "    print(f\"Augmented FPR ({name}):\", fpr_a)\n",
    "\n",
    "    # Compare against the corresponding baseline FPR if available\n",
    "    base_fpr = fpr_baseline.get(name) if isinstance(fpr_baseline, dict) else None\n",
    "    if base_fpr is not None:\n",
    "        print(\"Change in FPR vs baseline:\", fpr_a - base_fpr)\n",
    "\n",
    "    print(classification_report(y_test, y_pred_aug, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-M-x2SRQCGO",
    "outputId": "174f24bd-f46d-49bd-d39f-8ea673501e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a data analyst working with a pandas DataFrame named df.\n",
      "df has one row per credit card transaction, with these columns:\n",
      "\n",
      "- row_index: integer row id\n",
      "- trans_date_trans_time: datetime of transaction\n",
      "- cc_num: credit card number (user identifier)\n",
      "- merchant: merchant name\n",
      "- category: merchant category (e.g., 'grocery', 'gas_transport')\n",
      "- amt: transaction amount (float)\n",
      "- first, last: cardholder first and last name\n",
      "- gender: 'M' or 'F'\n",
      "- street, city, state, zip: cardholder address\n",
      "- lat, long: cardholder location coordinates\n",
      "- city_pop: population of cardholder's city\n",
      "- job: cardholder job title\n",
      "- dob: date of birth\n",
      "- trans_num: unique transaction ID\n",
      "- unix_time: unix timestamp of transaction\n",
      "- merch_lat, merch_long: merchant coordinates\n",
      "- merch_zipcode: merchant zipcode\n",
      "- is_fraud: 1 if transaction is fraudulent, 0 otherwise\n",
      "\n",
      "There is also a DataFrame user_profiles with one row per cc_num (user) and columns like:\n",
      "- cc_num\n",
      "- n_legit_tx, total_spent, mean_spent, max_spent, min_spent, median_spent\n",
      "- mean_lat, mean_long\n",
      "- main_city, main_state\n",
      "- cat_pct_<category> (fraction of legit txns in that category)\n",
      "- tb_pct_morning, tb_pct_afternoon, tb_pct_evening, tb_pct_night (time-of-day fractions)\n",
      "\n"
     ],
     "data": {}
    }
   ],
   "source": [
    "schema_description = \"\"\"\n",
    "You are a data analyst working with a pandas DataFrame named df.\n",
    "df has one row per credit card transaction, with these columns:\n",
    "\n",
    "- row_index: integer row id\n",
    "- trans_date_trans_time: datetime of transaction\n",
    "- cc_num: credit card number (user identifier)\n",
    "- merchant: merchant name\n",
    "- category: merchant category (e.g., 'grocery', 'gas_transport')\n",
    "- amt: transaction amount (float)\n",
    "- first, last: cardholder first and last name\n",
    "- gender: 'M' or 'F'\n",
    "- street, city, state, zip: cardholder address\n",
    "- lat, long: cardholder location coordinates\n",
    "- city_pop: population of cardholder's city\n",
    "- job: cardholder job title\n",
    "- dob: date of birth\n",
    "- trans_num: unique transaction ID\n",
    "- unix_time: unix timestamp of transaction\n",
    "- merch_lat, merch_long: merchant coordinates\n",
    "- merch_zipcode: merchant zipcode\n",
    "- is_fraud: 1 if transaction is fraudulent, 0 otherwise\n",
    "\n",
    "There is also a DataFrame user_profiles with one row per cc_num (user) and columns like:\n",
    "- cc_num\n",
    "- n_legit_tx, total_spent, mean_spent, max_spent, min_spent, median_spent\n",
    "- mean_lat, mean_long\n",
    "- main_city, main_state\n",
    "- cat_pct_<category> (fraction of legit txns in that category)\n",
    "- tb_pct_morning, tb_pct_afternoon, tb_pct_evening, tb_pct_night (time-of-day fractions)\n",
    "\"\"\"\n",
    "print(schema_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "B38_ijR3XmHc"
   },
   "outputs": [],
   "source": [
    "# We'll reuse gen_model and tokenizer from previous steps.\n",
    "# If you are in a fresh runtime, reload them as in Steps 9\u201311 first.\n",
    "\n",
    "def generate_pandas_code(question, max_new_tokens=256):\n",
    "    system_prompt = f\"\"\"\n",
    "{schema_description}\n",
    "\n",
    "You write ONLY executable Python code, without any explanation, comments, or backticks.\n",
    "\n",
    "Rules:\n",
    "- Use the pandas DataFrame df (raw data) and user_profiles when needed.\n",
    "- Do NOT import any modules (no import statements).\n",
    "- The final line of your code MUST assign the answer to a variable named result.\n",
    "- result can be a scalar, Series, DataFrame, or dictionary.\n",
    "- Use idiomatic pandas, e.g., groupby, sort_values, head, etc.\n",
    "- NEVER print anything.\n",
    "- Do NOT call input(), open(), eval(), exec(), or OS functions.\n",
    "\"\"\"\n",
    "    prompt = system_prompt + \"\\n\\nQuestion:\\n\" + question + \"\\n\\nPython code:\\n\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Keep only what comes after \"Python code:\"\n",
    "    if \"Python code:\" in text:\n",
    "        code = text.split(\"Python code:\")[-1].strip()\n",
    "    else:\n",
    "        code = text.strip()\n",
    "\n",
    "    # Very simple cleanup: remove leading/trailing code fences if any sneak in\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "fORmvq4JXqmp"
   },
   "outputs": [],
   "source": [
    "def answer_question(question, show_code=True):\n",
    "    code = generate_pandas_code(question)\n",
    "    if show_code:\n",
    "        print(\"\ud83d\udd27 Generated code:\\n\")\n",
    "        print(code)\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Restricted environment: only these names are available\n",
    "    local_env = {\n",
    "        \"df\": df,\n",
    "        \"user_profiles\": user_profiles,\n",
    "        \"pd\": pd,\n",
    "        \"np\": np\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        exec(code, {}, local_env)\n",
    "    except Exception as e:\n",
    "        print(\"\u274c Error while executing generated code:\", e)\n",
    "        return None\n",
    "\n",
    "    result = local_env.get(\"result\", None)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgxTlAqIXt0H",
    "outputId": "4d39cc48-95b8-4545-ac35-0c87f831fabd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ],
     "data": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd27 Generated code:\n",
      "\n",
      "# Import pandas\n",
      "import pandas as pd\n",
      "\n",
      "# Load raw data\n",
      "df = pd.read_csv('cc_transactions.csv')\n",
      "\n",
      "# Join user_profiles with df\n",
      "result = pd.merge(df, user_profiles, on='cc_num')\n",
      "\n",
      "# Group by category and sum amt\n",
      "grouped = result.groupby('category')['amt'].sum().sort_values(ascending=False)\n",
      "\n",
      "# Get top 10\n",
      "top_10 = grouped.head(10)\n",
      "\n",
      "# Assign to result\n",
      "result['top_merch_category'] = top_10.index\n",
      "\n",
      "# Print result\n",
      "print(result)\n",
      "\n",
      "\n",
      "Solution:\n",
      "\n",
      "The code reads the 'cc_transactions.csv' file and merges it with the 'user_profiles.csv' DataFrame. It then groups the DataFrame by 'category' and sums the 'amt' column. The top 10 categories by total transaction amount are assigned to a new column 'top_merch_category' in the'result' DataFrame. Finally, the'result' DataFrame is printed\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\u274c Error while executing generated code: invalid syntax (<string>, line 23)\n"
     ],
     "data": {}
    }
   ],
   "source": [
    "q2 = \"Show the top 10 merchant categories by total transaction amount.\"\n",
    "res2 = answer_question(q2)\n",
    "res2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "c307237e",
    "outputId": "cf3f4374-72ee-4ff3-9e5e-bea854a606ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"duckdb_conn\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"n_rows\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1296675,\n        \"max\": 1296675,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1296675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8298c59b-4da2-45cd-a28f-f12c91cc0b9e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1296675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8298c59b-4da2-45cd-a28f-f12c91cc0b9e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8298c59b-4da2-45cd-a28f-f12c91cc0b9e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8298c59b-4da2-45cd-a28f-f12c91cc0b9e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    n_rows\n",
       "0  1296675"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install and set up DuckDB, then register df as a SQL table\n",
    "\n",
    "!pip install -q duckdb\n",
    "\n",
    "import duckdb\n",
    "\n",
    "# In-memory DuckDB database connection\n",
    "duckdb_conn = duckdb.connect(database=\":memory:\")\n",
    "\n",
    "# Register the full dataframe as a table named `transactions`\n",
    "# Assumes `df` is already loaded earlier in the notebook\n",
    "duckdb_conn.register(\"transactions\", df)\n",
    "\n",
    "# Quick sanity check\n",
    "duckdb_conn.execute(\"SELECT COUNT(*) AS n_rows FROM transactions\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "0f81e4df"
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "import re\n",
    "\n",
    "SCHEMA_DESCRIPTION_SQL = dedent(\"\"\"\n",
    "You are given a SQL table named `transactions` in DuckDB with the following columns:\n",
    "\n",
    "- row_index              : integer index\n",
    "- trans_date_trans_time  : transaction timestamp (timestamp)\n",
    "- cc_num                 : credit card number (integer or big integer)\n",
    "- merchant               : merchant name (string)\n",
    "- category               : merchant category (string)\n",
    "- amt                    : transaction amount (double/float)\n",
    "- first                  : first name of cardholder\n",
    "- last                   : last name of cardholder\n",
    "- gender                 : gender of cardholder\n",
    "- street                 : street address\n",
    "- city                   : city name\n",
    "- state                  : state code\n",
    "- zip                    : ZIP code (integer, can be null)\n",
    "- lat                    : latitude of cardholder\n",
    "- long                   : longitude of cardholder\n",
    "- city_pop               : population of the city\n",
    "- job                    : job title\n",
    "- dob                    : date of birth (date)\n",
    "- trans_num              : transaction ID\n",
    "- unix_time              : unix timestamp of the transaction (bigint)\n",
    "- merch_lat              : merchant latitude\n",
    "- merch_long             : merchant longitude\n",
    "- is_fraud               : 0 for legitimate, 1 for fraud\n",
    "- merch_zipcode          : merchant ZIP code\n",
    "\n",
    "Database: DuckDB SQL dialect.\n",
    "\n",
    "Important rules:\n",
    "- Use ONLY the `transactions` table.\n",
    "- Use ONLY SELECT queries. Do NOT use INSERT, UPDATE, DELETE, DROP, ALTER, TRUNCATE, CREATE, or any DDL/DML.\n",
    "- You may use WHERE, GROUP BY, HAVING, ORDER BY, LIMIT, aggregates (SUM, AVG, COUNT, etc.).\n",
    "- When filtering legitimate transactions, use `is_fraud = 0`.\n",
    "- When filtering fraudulent transactions, use `is_fraud = 1`.\n",
    "- If aggregating, use clear aliases (e.g., `AS total_amount`, `AS fraud_rate`).\n",
    "- The query should be complete and directly executable.\n",
    "- Output ONLY the SQL query, without explanations or comments.\n",
    "\"\"\")\n",
    "\n",
    "def build_sql_prompt(question: str) -> str:\n",
    "    return dedent(f\"\"\"\n",
    "    You are a data analyst who writes SQL queries.\n",
    "\n",
    "    {SCHEMA_DESCRIPTION_SQL}\n",
    "\n",
    "    Question from the user:\n",
    "    {question}\n",
    "\n",
    "    Write a single DuckDB SQL SELECT query on the `transactions` table that answers the question.\n",
    "    Return ONLY the SQL query. Do NOT include any explanations, comments, or conversational text.\n",
    "    Your response MUST start with `SELECT` and end with a semicolon.\n",
    "    ---SQL_START---\n",
    "    \"\"\")\n",
    "\n",
    "def extract_sql_from_text(generated_text: str) -> str:\n",
    "    \"\"\"Extract SQL from optional markdown fences, else return raw text.\"\"\"\n",
    "\n",
    "    # 1. Strip common LLM conversational/prompt artifacts first\n",
    "    cleaned_text = generated_text\n",
    "    cleaned_text = cleaned_text.split('<|question_end|>', 1)[-1] if '<|question_end|>' in cleaned_text else cleaned_text\n",
    "    cleaned_text = cleaned_text.split('Solution:', 1)[-1] if 'Solution:' in cleaned_text else cleaned_text\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    # 2. Try to extract SQL enclosed within the explicit markers\n",
    "    sql_marker_match = re.search(r\"---SQL_START---\\s*(.*?)\\s*---SQL_END---\", cleaned_text, re.DOTALL | re.IGNORECASE)\n",
    "    if sql_marker_match:\n",
    "        return sql_marker_match.group(1).strip()\n",
    "\n",
    "    # 3. Prioritize specific 'sql' markdown blocks\n",
    "    sql_block_match = re.search(r\"```sql\\n(.*?)\\n```\", cleaned_text, re.DOTALL | re.IGNORECASE)\n",
    "    if sql_block_match:\n",
    "        return sql_block_match.group(1).strip()\n",
    "\n",
    "    # 4. If no 'sql' block, look for any generic markdown code block.\n",
    "    #    If it's not explicitly SQL, we assume it's not the desired output\n",
    "    #    and will try to find a bare SELECT statement later.\n",
    "    generic_code_blocks = re.findall(r\"```(?:\\w+)?\\n(.*?)\\n```\", cleaned_text, re.DOTALL)\n",
    "    for block_content in generic_code_blocks:\n",
    "        # Heuristic: if it looks like SQL (contains SELECT, FROM, GROUP BY, etc.)\n",
    "        # and doesn't look like Python (no 'import', 'def', 'class')\n",
    "        if (re.search(r\"\\bSELECT\\b|\\bFROM\\b|\\bWHERE\\b|\\bGROUP BY\\b|\\bORDER BY\\b\", block_content, re.IGNORECASE)\n",
    "            and not re.search(r\"\\bimport\\b|\\bdef\\b|\\bclass\\b|\\bprint\\b\", block_content)):\n",
    "            return block_content.strip()\n",
    "\n",
    "    # 5. If no markdown blocks yielded SQL, or if they were non-SQL blocks,\n",
    "    #    remove all markdown code blocks from the text and then search for a bare SELECT statement.\n",
    "    text_without_code_blocks = re.sub(r\"```.*?```\", \"\", cleaned_text, flags=re.DOTALL)\n",
    "\n",
    "    sql_match = re.search(r\"^\\s*(SELECT.*?)(?:;|$)\", text_without_code_blocks, re.DOTALL | re.IGNORECASE)\n",
    "    if sql_match:\n",
    "        return sql_match.group(1).strip()\n",
    "\n",
    "    # Final fallback: if nothing worked, return an empty string\n",
    "    return \"\"\n",
    "\n",
    "def generate_sql_query(question: str, max_new_tokens: int = 256, temperature: float = 0.2) -> str:\n",
    "    \"\"\"Use the fine-tuned LLM to generate a DuckDB SQL query for the question.\"\"\"\n",
    "    prompt = build_sql_prompt(question)\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # In case the model echoes the prompt, keep only what comes after it\n",
    "    if prompt in text:\n",
    "        sql = text.split(prompt, 1)[-1].strip()\n",
    "    else:\n",
    "        sql = text.strip()\n",
    "\n",
    "    sql = extract_sql_from_text(sql)\n",
    "\n",
    "    # Ensure the generated SQL ends with a semicolon and add the closing marker\n",
    "    if not sql.endswith(';'):\n",
    "        sql += ';'\n",
    "    sql += '\\n---SQL_END---'\n",
    "\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "vrrHkfXerPqJ"
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "import re\n",
    "\n",
    "SCHEMA_DESCRIPTION_SQL = dedent(\"\"\"\n",
    "You are given a SQL table named `transactions` in DuckDB with the following columns:\n",
    "\n",
    "- row_index              : integer index\n",
    "- trans_date_trans_time  : transaction timestamp (timestamp)\n",
    "- cc_num                 : credit card number (integer or big integer)\n",
    "- merchant               : merchant name (string)\n",
    "- category               : merchant category (string)\n",
    "- amt                    : transaction amount (double/float)\n",
    "- first                  : first name of cardholder\n",
    "- last                   : last name of cardholder\n",
    "- gender                 : gender of cardholder\n",
    "- street                 : street address\n",
    "- city                   : city name\n",
    "- state                  : state code\n",
    "- zip                    : ZIP code (integer, can be null)\n",
    "- lat                    : latitude of cardholder\n",
    "- long                   : longitude of cardholder\n",
    "- city_pop               : population of the city\n",
    "- job                    : job title\n",
    "- dob                    : date of birth (date)\n",
    "- trans_num              : transaction ID\n",
    "- unix_time              : unix timestamp of the transaction (bigint)\n",
    "- merch_lat              : merchant latitude\n",
    "- merch_long             : merchant longitude\n",
    "- is_fraud               : 0 for legitimate, 1 for fraud\n",
    "- merch_zipcode          : merchant ZIP code\n",
    "\n",
    "Database: DuckDB SQL dialect.\n",
    "\n",
    "Important rules:\n",
    "- Use ONLY the `transactions` table.\n",
    "- Use ONLY SELECT queries. Do NOT use INSERT, UPDATE, DELETE, DROP, ALTER, TRUNCATE, CREATE, or any DDL/DML.\n",
    "- You may use WHERE, GROUP BY, HAVING, ORDER BY, LIMIT, aggregates (SUM, AVG, COUNT, etc.).\n",
    "- When filtering legitimate transactions, use `is_fraud = 0`.\n",
    "- When filtering fraudulent transactions, use `is_fraud = 1`.\n",
    "- If aggregating, use clear aliases (e.g., `AS total_amount`, `AS fraud_rate`).\n",
    "- The query should be complete and directly executable.\n",
    "- Output ONLY the SQL query, without explanations or comments.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def build_sql_prompt(question: str) -> str:\n",
    "    return dedent(f\"\"\"\n",
    "    You are a data analyst who writes SQL queries.\n",
    "\n",
    "    {SCHEMA_DESCRIPTION_SQL}\n",
    "\n",
    "    Question from the user:\n",
    "    \\\"\\\"\\\"{question}\\\"\\\"\\\"\n",
    "\n",
    "    Write a single DuckDB SQL SELECT query on the `transactions` table that answers the question.\n",
    "    Follow the rules strictly and output only the SQL query.\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "def extract_sql_from_text(generated_text: str) -> str:\n",
    "    \"\"\"Extract SQL from optional markdown fences, else return raw text.\"\"\"\n",
    "    sql_block = re.search(r\"```sql(.*?)```\", generated_text, re.DOTALL | re.IGNORECASE)\n",
    "    if sql_block:\n",
    "        return sql_block.group(1).strip()\n",
    "    sql_block = re.search(r\"```(.*?)```\", generated_text, re.DOTALL)\n",
    "    if sql_block:\n",
    "        return sql_block.group(1).strip()\n",
    "    return generated_text.strip()\n",
    "\n",
    "\n",
    "def generate_sql_query(question: str, max_new_tokens: int = 256, temperature: float = 0.2) -> str:\n",
    "    \"\"\"Use the fine-tuned LLM to generate a DuckDB SQL query for the question.\"\"\"\n",
    "    prompt = build_sql_prompt(question)\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # In case the model echoes the prompt, keep only what comes after it\n",
    "    if prompt in text:\n",
    "        sql = text.split(prompt, 1)[-1].strip()\n",
    "    else:\n",
    "        sql = text.strip()\n",
    "\n",
    "    sql = extract_sql_from_text(sql)\n",
    "    return sql"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}